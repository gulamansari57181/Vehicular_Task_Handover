{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing The Libraries"
      ],
      "metadata": {
        "id": "jolLt2UvU5Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Input\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nGdyUS7-XFGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Simulation Parameters\n"
      ],
      "metadata": {
        "id": "pjEh1GBgXNFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation Parameters (Defined as per research paper)\n",
        "NUM_VEHICLES = 80\n",
        "NUM_RSUS = 30\n",
        "ROAD_LENGTH_KM = 10\n",
        "VEHICLE_SPEED_RANGE = (30, 120)  # km/h\n",
        "COMMUNICATION_RANGE = 200  # meters\n",
        "VEHICLE_CPU_RANGE = (2, 8)  # GHz\n",
        "RSU_CPU_RANGE = (8, 16)  # GHz\n",
        "TASK_SIZE = 16  # Mbits\n",
        "PROCESSING_OVERHEAD = 1000  # cycles/bit\n",
        "BANDWIDTH = 10  # MHz\n",
        "POWER_CONSUMPTION_COEFFICIENT = 1e-27  # W·s³/cycles³\n",
        "GAMMA = 0.9  # Discount factor\n",
        "EPSILON = 0.9  # Exploration rate\n",
        "BATCH_SIZE = 32\n",
        "UPDATE_TARGET_EVERY = 50\n",
        "EPISODES = 256\n"
      ],
      "metadata": {
        "id": "W__-PfdyXSYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method to calculate Energy Consumption and Delay"
      ],
      "metadata": {
        "id": "cFKgUgXFXi8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate energy consumption\n",
        "def calculate_energy(cpu_cycles, cpu_frequency):\n",
        "    return POWER_CONSUMPTION_COEFFICIENT * cpu_cycles * (cpu_frequency ** 2)\n",
        "\n",
        "# Function to calculate delay\n",
        "def calculate_delay(task_size, bandwidth):\n",
        "    return task_size / bandwidth"
      ],
      "metadata": {
        "id": "qzcxOIbdXncA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method To build Model"
      ],
      "metadata": {
        "id": "e6XFZDvlXzhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(state_size, action_size):\n",
        "    inputs = Input(shape=(state_size,))\n",
        "    x = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(action_size, activation=\"linear\")(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "hEgPhGOMX2Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " To define Vehicular Offloading Environment"
      ],
      "metadata": {
        "id": "0I6iEiAhX40R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Define Vehicular Offloading Environment\n",
        "class VehicularOffloadingEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(VehicularOffloadingEnv, self).__init__()\n",
        "\n",
        "        self.observation_space = spaces.Box(low=np.array([VEHICLE_SPEED_RANGE[0], VEHICLE_CPU_RANGE[0], RSU_CPU_RANGE[0], 0]),\n",
        "                                            high=np.array([VEHICLE_SPEED_RANGE[1], VEHICLE_CPU_RANGE[1], RSU_CPU_RANGE[1], COMMUNICATION_RANGE]), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        self.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        delay = calculate_delay(TASK_SIZE, BANDWIDTH)\n",
        "        energy = calculate_energy(PROCESSING_OVERHEAD * TASK_SIZE, VEHICLE_CPU_RANGE[1] if action == 0 else RSU_CPU_RANGE[1])\n",
        "        cost = delay + energy + np.random.uniform(-0.5, 0.5)  # Adding slight randomness\n",
        "        reward = -cost  # Minimize cost\n",
        "        next_state = self.observation_space.sample()\n",
        "        done = False  # Continuous scenario\n",
        "        return next_state, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        return self.observation_space.sample()\n",
        "\n",
        "env = VehicularOffloadingEnv()\n",
        "\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "policy_model = build_model(state_size, action_size)\n",
        "target_model = build_model(state_size, action_size)\n",
        "target_model.set_weights(policy_model.get_weights())\n",
        "\n",
        "def update_policy():\n",
        "    if len(replay_memory) < BATCH_SIZE:\n",
        "        return\n",
        "    batch = random.sample(replay_memory, BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones = zip(*batch)\n",
        "    states, next_states = np.array(states), np.array(next_states)\n",
        "\n",
        "    q_values_next = policy_model.predict(next_states, verbose=0)\n",
        "    q_values_target = target_model.predict(next_states, verbose=0)\n",
        "    q_values = policy_model.predict(states, verbose=0)\n",
        "\n",
        "    for i in range(BATCH_SIZE):\n",
        "        best_action = np.argmax(q_values_next[i])\n",
        "        target = rewards[i] if dones[i] else rewards[i] + GAMMA * q_values_target[i][best_action]\n",
        "        q_values[i][actions[i]] = target\n",
        "\n",
        "    policy_model.fit(states, q_values, verbose=0, batch_size=BATCH_SIZE)\n",
        "\n",
        "replay_memory = []\n",
        "rewards_history = []\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    L = TASK_SIZE\n",
        "\n",
        "    while L > 0:\n",
        "        if random.random() < EPSILON:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            q_values = policy_model.predict(state.reshape(1, -1), verbose=0)\n",
        "            action = np.argmax(q_values[0])\n",
        "\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        replay_memory.append((state, action, reward, next_state, done))\n",
        "        if len(replay_memory) > 2000:\n",
        "            replay_memory.pop(0)\n",
        "\n",
        "        update_policy()\n",
        "\n",
        "        if episode % UPDATE_TARGET_EVERY == 0:\n",
        "            target_model.set_weights(policy_model.get_weights())\n",
        "\n",
        "        L -= 1\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    rewards_history.append(total_reward)\n",
        "    EPSILON = max(0.1, EPSILON * 0.995)\n",
        "    print(f\"Episode {episode+1}: Total Reward = {total_reward}\")\n",
        "\n",
        "plt.plot(rewards_history)\n",
        "plt.xlabel(\"Episodes\")\n",
        "plt.ylabel(\"Total Reward\")\n",
        "plt.title(\"DDQN Training Performance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBVOi_Yja4CV",
        "outputId": "a42d26df-1336-4191-cbe1-757fc6eddeb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: Total Reward = -25.180805657674007\n",
            "Episode 2: Total Reward = -25.439667883956474\n",
            "Episode 3: Total Reward = -24.39159026239767\n",
            "Episode 4: Total Reward = -26.338143939577044\n",
            "Episode 5: Total Reward = -24.394315282128915\n",
            "Episode 6: Total Reward = -24.91191017280461\n",
            "Episode 7: Total Reward = -26.32512313657124\n",
            "Episode 8: Total Reward = -25.890713460587005\n",
            "Episode 9: Total Reward = -26.75741494117814\n",
            "Episode 10: Total Reward = -25.618136853954297\n",
            "Episode 11: Total Reward = -24.694091232603867\n",
            "Episode 12: Total Reward = -25.863547643490175\n",
            "Episode 13: Total Reward = -25.810608061647425\n",
            "Episode 14: Total Reward = -26.12530466791838\n",
            "Episode 15: Total Reward = -25.149749437706014\n",
            "Episode 16: Total Reward = -24.27082140722535\n",
            "Episode 17: Total Reward = -26.486866109563547\n",
            "Episode 18: Total Reward = -24.96145088836847\n",
            "Episode 19: Total Reward = -23.472038713127954\n",
            "Episode 20: Total Reward = -24.49247444575023\n",
            "Episode 21: Total Reward = -25.31459429584846\n",
            "Episode 22: Total Reward = -24.9587041424562\n",
            "Episode 23: Total Reward = -24.623846159702367\n",
            "Episode 24: Total Reward = -26.824419562148755\n",
            "Episode 25: Total Reward = -24.574817545193724\n",
            "Episode 26: Total Reward = -25.713386476503278\n",
            "Episode 27: Total Reward = -23.66870102605472\n",
            "Episode 28: Total Reward = -27.768433875816157\n",
            "Episode 29: Total Reward = -26.40272510697298\n",
            "Episode 30: Total Reward = -23.467705396514482\n",
            "Episode 31: Total Reward = -26.097658071017772\n",
            "Episode 32: Total Reward = -23.9428812298771\n",
            "Episode 33: Total Reward = -26.234722392422835\n",
            "Episode 34: Total Reward = -22.772637475204014\n",
            "Episode 35: Total Reward = -26.71130921526674\n",
            "Episode 36: Total Reward = -25.855258954512422\n",
            "Episode 37: Total Reward = -25.68862811674517\n",
            "Episode 38: Total Reward = -25.59814701739154\n",
            "Episode 39: Total Reward = -24.063813639188613\n",
            "Episode 40: Total Reward = -25.167873000183178\n",
            "Episode 41: Total Reward = -25.108123298862854\n",
            "Episode 42: Total Reward = -25.028663973768335\n",
            "Episode 43: Total Reward = -26.6947065178412\n",
            "Episode 44: Total Reward = -25.10155279773782\n",
            "Episode 45: Total Reward = -27.6577937362495\n",
            "Episode 46: Total Reward = -27.31348051522976\n",
            "Episode 47: Total Reward = -23.487360023522008\n",
            "Episode 48: Total Reward = -26.359977488206376\n",
            "Episode 49: Total Reward = -25.704946901099934\n",
            "Episode 50: Total Reward = -26.158205094476617\n",
            "Episode 51: Total Reward = -23.379610215629427\n",
            "Episode 52: Total Reward = -23.76578804920014\n",
            "Episode 53: Total Reward = -26.467211935859936\n",
            "Episode 54: Total Reward = -25.193480259040072\n",
            "Episode 55: Total Reward = -26.120762711472594\n",
            "Episode 56: Total Reward = -24.47362945412845\n",
            "Episode 57: Total Reward = -24.98211455786973\n",
            "Episode 58: Total Reward = -25.488054492416047\n",
            "Episode 59: Total Reward = -25.01927169772129\n",
            "Episode 60: Total Reward = -24.13292209622085\n",
            "Episode 61: Total Reward = -27.611643622034833\n",
            "Episode 62: Total Reward = -24.80545438163114\n",
            "Episode 63: Total Reward = -27.594180698269152\n",
            "Episode 64: Total Reward = -25.114661123626828\n",
            "Episode 65: Total Reward = -26.25732274081109\n",
            "Episode 66: Total Reward = -26.18206885216727\n",
            "Episode 67: Total Reward = -27.600942139293483\n",
            "Episode 68: Total Reward = -24.608606116685753\n",
            "Episode 69: Total Reward = -27.726179594263634\n",
            "Episode 70: Total Reward = -25.126173648480595\n",
            "Episode 71: Total Reward = -26.207035027393292\n",
            "Episode 72: Total Reward = -25.664391699454093\n",
            "Episode 73: Total Reward = -26.755598374190683\n",
            "Episode 74: Total Reward = -26.206572606631788\n",
            "Episode 75: Total Reward = -25.60471224876675\n",
            "Episode 76: Total Reward = -26.18247917364141\n",
            "Episode 77: Total Reward = -27.10621017426773\n",
            "Episode 78: Total Reward = -25.716620672610407\n",
            "Episode 79: Total Reward = -25.76559791726787\n",
            "Episode 80: Total Reward = -25.910045139472793\n",
            "Episode 81: Total Reward = -26.779109324794053\n",
            "Episode 82: Total Reward = -26.345403266033045\n",
            "Episode 83: Total Reward = -24.297202681033014\n",
            "Episode 84: Total Reward = -25.477495934253987\n",
            "Episode 85: Total Reward = -26.704462052938432\n",
            "Episode 86: Total Reward = -25.764402619796357\n",
            "Episode 87: Total Reward = -28.260124409862936\n",
            "Episode 88: Total Reward = -25.926920336226257\n",
            "Episode 89: Total Reward = -24.619003890607345\n",
            "Episode 90: Total Reward = -25.263119363457744\n",
            "Episode 91: Total Reward = -26.15173696348241\n",
            "Episode 92: Total Reward = -26.468379921791723\n",
            "Episode 93: Total Reward = -27.887235941797975\n",
            "Episode 94: Total Reward = -25.058202154265025\n",
            "Episode 95: Total Reward = -24.963773444527995\n",
            "Episode 96: Total Reward = -26.471471610663382\n",
            "Episode 97: Total Reward = -25.223286818876257\n",
            "Episode 98: Total Reward = -24.64812933483085\n",
            "Episode 99: Total Reward = -23.73975538782557\n",
            "Episode 100: Total Reward = -24.76313446609823\n",
            "Episode 101: Total Reward = -25.441211861754837\n",
            "Episode 102: Total Reward = -26.034163367726123\n",
            "Episode 103: Total Reward = -25.85716781231652\n",
            "Episode 104: Total Reward = -26.35610395910465\n",
            "Episode 105: Total Reward = -24.364892617597114\n",
            "Episode 106: Total Reward = -26.49896507085347\n",
            "Episode 107: Total Reward = -23.536182025605623\n",
            "Episode 108: Total Reward = -24.771115383859904\n",
            "Episode 109: Total Reward = -28.53828761980687\n",
            "Episode 110: Total Reward = -24.961482932703866\n",
            "Episode 111: Total Reward = -25.378356708117753\n",
            "Episode 112: Total Reward = -24.658696914864965\n",
            "Episode 113: Total Reward = -25.672969216710094\n",
            "Episode 114: Total Reward = -24.41385756943118\n",
            "Episode 115: Total Reward = -27.461866305285767\n",
            "Episode 116: Total Reward = -25.810948807022797\n",
            "Episode 117: Total Reward = -27.121471130200614\n",
            "Episode 118: Total Reward = -25.279826716067756\n",
            "Episode 119: Total Reward = -25.60965307986808\n",
            "Episode 120: Total Reward = -25.26717769535709\n",
            "Episode 121: Total Reward = -25.318768242817637\n",
            "Episode 122: Total Reward = -27.389772441315213\n",
            "Episode 123: Total Reward = -24.392347490467547\n",
            "Episode 124: Total Reward = -23.974268528518852\n",
            "Episode 125: Total Reward = -26.369777051393484\n",
            "Episode 126: Total Reward = -24.148129989595304\n",
            "Episode 127: Total Reward = -25.43695036974335\n",
            "Episode 128: Total Reward = -26.244196470988\n",
            "Episode 129: Total Reward = -24.322162129526205\n",
            "Episode 130: Total Reward = -23.923602379735826\n",
            "Episode 131: Total Reward = -23.67006695043712\n",
            "Episode 132: Total Reward = -25.493394685093946\n",
            "Episode 133: Total Reward = -25.0284489185972\n",
            "Episode 134: Total Reward = -29.1635536388932\n",
            "Episode 135: Total Reward = -25.244524484874756\n",
            "Episode 136: Total Reward = -26.413250469340365\n",
            "Episode 137: Total Reward = -27.757818389988877\n",
            "Episode 138: Total Reward = -25.99900206832006\n",
            "Episode 139: Total Reward = -24.28978227327928\n",
            "Episode 140: Total Reward = -26.756059139926247\n",
            "Episode 141: Total Reward = -23.90480192875569\n",
            "Episode 142: Total Reward = -28.00233127820447\n",
            "Episode 143: Total Reward = -27.657922045658136\n",
            "Episode 144: Total Reward = -26.521206868541654\n",
            "Episode 145: Total Reward = -25.650051756213518\n",
            "Episode 146: Total Reward = -25.32340612787546\n",
            "Episode 147: Total Reward = -23.54040673382971\n",
            "Episode 148: Total Reward = -27.870234764996336\n",
            "Episode 149: Total Reward = -26.530773697239606\n",
            "Episode 150: Total Reward = -26.102027130358174\n",
            "Episode 151: Total Reward = -25.98009520667925\n",
            "Episode 152: Total Reward = -24.483936067396847\n",
            "Episode 153: Total Reward = -24.446012984415905\n",
            "Episode 154: Total Reward = -25.014008592372846\n",
            "Episode 155: Total Reward = -24.40999730533502\n",
            "Episode 156: Total Reward = -25.288796263601075\n",
            "Episode 157: Total Reward = -25.07504012155196\n",
            "Episode 158: Total Reward = -25.528012006406403\n",
            "Episode 159: Total Reward = -28.250844695943147\n",
            "Episode 160: Total Reward = -25.377851603878113\n",
            "Episode 161: Total Reward = -25.84257261676244\n",
            "Episode 162: Total Reward = -26.183938044926492\n",
            "Episode 163: Total Reward = -25.192277926217404\n",
            "Episode 164: Total Reward = -24.682616757282574\n",
            "Episode 165: Total Reward = -23.61498497555628\n",
            "Episode 166: Total Reward = -25.64827698060762\n",
            "Episode 167: Total Reward = -25.32916996862269\n",
            "Episode 168: Total Reward = -23.807408091416995\n",
            "Episode 169: Total Reward = -24.520910913162837\n",
            "Episode 170: Total Reward = -25.740266327664028\n",
            "Episode 171: Total Reward = -25.513828939180012\n",
            "Episode 172: Total Reward = -24.932145925972208\n",
            "Episode 173: Total Reward = -25.170292421010878\n",
            "Episode 174: Total Reward = -26.59011475587293\n",
            "Episode 175: Total Reward = -25.482621124303947\n",
            "Episode 176: Total Reward = -26.09839812470409\n",
            "Episode 177: Total Reward = -24.779099462166382\n",
            "Episode 178: Total Reward = -24.41403730754165\n",
            "Episode 179: Total Reward = -23.528158945384565\n",
            "Episode 180: Total Reward = -23.032938233707405\n",
            "Episode 181: Total Reward = -25.618205599717587\n",
            "Episode 182: Total Reward = -25.63864152820584\n",
            "Episode 183: Total Reward = -25.527612228227696\n",
            "Episode 184: Total Reward = -27.80833753663319\n",
            "Episode 185: Total Reward = -25.587525069106857\n",
            "Episode 186: Total Reward = -24.650159870762852\n",
            "Episode 187: Total Reward = -25.348715778944488\n",
            "Episode 188: Total Reward = -25.85985102263459\n",
            "Episode 189: Total Reward = -24.65708938476644\n",
            "Episode 190: Total Reward = -25.608086761580655\n",
            "Episode 191: Total Reward = -24.977068337299453\n",
            "Episode 192: Total Reward = -23.806433247610535\n",
            "Episode 193: Total Reward = -25.411760048211157\n",
            "Episode 194: Total Reward = -24.175568487978474\n",
            "Episode 195: Total Reward = -25.694410245814275\n",
            "Episode 196: Total Reward = -25.434525452971954\n",
            "Episode 197: Total Reward = -25.619215543637907\n",
            "Episode 198: Total Reward = -27.36155171904513\n",
            "Episode 199: Total Reward = -26.0883826793101\n",
            "Episode 200: Total Reward = -24.6338763192489\n",
            "Episode 201: Total Reward = -23.738510618229185\n",
            "Episode 202: Total Reward = -25.0423191847148\n",
            "Episode 203: Total Reward = -26.11729067445942\n",
            "Episode 204: Total Reward = -26.1980489551196\n",
            "Episode 205: Total Reward = -26.55819789358881\n",
            "Episode 206: Total Reward = -24.944651559414506\n",
            "Episode 207: Total Reward = -25.28488505482514\n",
            "Episode 208: Total Reward = -22.418974406815792\n",
            "Episode 209: Total Reward = -25.99487355192712\n",
            "Episode 210: Total Reward = -26.510545930501934\n",
            "Episode 211: Total Reward = -22.176332290264952\n",
            "Episode 212: Total Reward = -27.060808247709843\n",
            "Episode 213: Total Reward = -27.082990460377722\n",
            "Episode 214: Total Reward = -25.382626631520644\n",
            "Episode 215: Total Reward = -25.347507944805148\n",
            "Episode 216: Total Reward = -27.587976655934654\n",
            "Episode 217: Total Reward = -26.772700183786345\n",
            "Episode 218: Total Reward = -24.80060983417241\n",
            "Episode 219: Total Reward = -27.366267904525472\n",
            "Episode 220: Total Reward = -26.067719781642577\n",
            "Episode 221: Total Reward = -26.92119854959771\n",
            "Episode 222: Total Reward = -26.9726372731135\n",
            "Episode 223: Total Reward = -26.89527544179236\n",
            "Episode 224: Total Reward = -25.404918129717558\n",
            "Episode 225: Total Reward = -25.53384838446784\n",
            "Episode 226: Total Reward = -26.564856472748858\n",
            "Episode 227: Total Reward = -25.49849622862964\n",
            "Episode 228: Total Reward = -26.413306255120425\n",
            "Episode 229: Total Reward = -27.281146263293284\n",
            "Episode 230: Total Reward = -25.635502518609627\n",
            "Episode 231: Total Reward = -24.559463900233446\n",
            "Episode 232: Total Reward = -23.714621349141137\n",
            "Episode 233: Total Reward = -25.47511095973721\n",
            "Episode 234: Total Reward = -25.594888156029718\n",
            "Episode 235: Total Reward = -25.885201421965608\n",
            "Episode 236: Total Reward = -27.529158637547578\n",
            "Episode 237: Total Reward = -25.883808511355653\n",
            "Episode 238: Total Reward = -26.937598140362862\n",
            "Episode 239: Total Reward = -26.056973898555036\n",
            "Episode 240: Total Reward = -25.835282931790807\n",
            "Episode 241: Total Reward = -25.23800626135137\n",
            "Episode 242: Total Reward = -25.43873957813593\n",
            "Episode 243: Total Reward = -25.19908027335509\n",
            "Episode 244: Total Reward = -26.986259008321763\n",
            "Episode 245: Total Reward = -25.426058663181173\n",
            "Episode 246: Total Reward = -23.932446351739316\n",
            "Episode 247: Total Reward = -25.190440380746086\n",
            "Episode 248: Total Reward = -26.296363737067352\n",
            "Episode 249: Total Reward = -24.459595483708778\n",
            "Episode 250: Total Reward = -24.993907928144914\n",
            "Episode 251: Total Reward = -26.630986869073027\n",
            "Episode 252: Total Reward = -25.24198112024783\n",
            "Episode 253: Total Reward = -25.02572307993987\n",
            "Episode 254: Total Reward = -25.04333819851492\n",
            "Episode 255: Total Reward = -27.058296231274824\n",
            "Episode 256: Total Reward = -27.334534347227013\n"
          ]
        }
      ]
    }
  ]
}